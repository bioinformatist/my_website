+++
title = "16S流程重构建"
date = 2018-07-27T09:39:35+08:00
draft = false

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ['16S rDNA测序']

# Project summary to display on homepage.
summary = ""

# Optional image to display on homepage.
image_preview = ""

# Optional external URL for project (replaces project detail page).
external_link = ""

# Does the project detail page use math formatting?
math = false

# Does the project detail page use source code highlighting?
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
[header]
image = ""
caption = ""

+++

## 第一部分： reads -> contigs、demux并统计

脚本start2SummaryContigs.batch的内容：

```shell
# make.file(inputdir=., type=fastq, prefix=GF)
make.contigs(ffastq=LZW113_1.fastq, rfastq=LZW113_2.fastq, oligos=oligos.txt, pdiffs=6, bdiffs=1, checkorient=t, processors=56)
summary.seqs(fasta=LZW113_1.trim.contigs.fasta)
```

这里注意几点：

1. 流程之后是肯定要用[Nextflow](https://www.nextflow.io/)重构的。比如这里的LZW113_1.fastq等等文件名将来会作为参数传递进来的。
2. SOP里面使用了一个`make.file()`去生成数据文件列表。但是经过实测，这一用法配合`oligos`参数去demux的话，是无法输出正确的结果的（双向fastq程序傻傻分不清楚）。所以**只能在`make.contigs()`手动指定`ffastq`和`rfastq`**。
3. 其实无需后面再通过trim.seqs()中指定`oligos`参数去demux，这一步**（`make.contigs()`）就支持指定`oligos`参数来提供barcodes信息，可以直接完成demux**，也减少了下游分析中可能出现的错误。
4. 应该通过设置`checkorient=t`来开启反向检测，如果出现reads和barcode的方向不一致（获得的正确序列很少），那么mothur会自动反向查询。
5. 这一步中，可以直接设置`allfiles=t`来将完成demux的序列分开文件输出。虽然mothur有groups文件，但是这比较方便后期直接针对单样本进行分析。本例中不开启这个参数，本质上后期也可以`split.groups()`来完成这个操作。
6. 有关`oligos`参数的问题。

> 此处我此前的理解有误，要多谢志伟师兄更正。`oligos`文件给出的primers是扩增引物，而并非测序的adapters。对于目前最普遍的Illumina系列产品为代表的二代测序而言，通常大家能够容忍的程度是6%，也就是，pair-ends测序，100个碱基内希望见到不超过6个碱基的错误。我们扩增V45区域使用的引物对是*GTGCCAGCMGCCGCGGTAA* 和*CCCCGYCAATTCMTTTRAGT* ，其中有**4**个简并碱基，而primers总长度是19 * 2 = 38，38 * 0.06 = 2.28个碱基，这样算多指定2个错配不过分。因此最后决定设置`pdiffs=6`。
    
那么，流程的第一部分大概就这样。之所以选择在这里截断流程一次，是因为summary之后需要根据统计得到的reads的长度分布去修改下一阶段使用的脚本内的参数（比如`maxlength`）。
    
使用时，可以比如`nohup mothur start2SummaryContigs.batch > step1.log &`这样。

## 第二部分： 提取高变区对应的参考序列

这部分参考[上次组会汇报的内容]({{< ref "talk/20180721-16s.zh.md" >}})。

## 第三部分： 过滤、去冗余、计数、比对并统计

脚本screen2SummaryCounts.batch的内容：

```shell
screen.seqs(fasta=LZW113_1.trim.contigs.fasta, group=LZW113_1.contigs.groups, summary=LZW113_1.trim.contigs.summary, maxambig=0, maxlength=450)
summary.seqs()
unique.seqs(fasta=LZW113_1.trim.contigs.good.fasta)
count.seqs(name=LZW113_1.trim.contigs.good.names, group=LZW113_1.contigs.good.groups)
summary.seqs(count=LZW113_1.trim.contigs.good.count_table)
align.seqs(fasta=LZW113_1.trim.contigs.good.unique.fasta, reference=silva.v45.fasta)
summary.seqs(fasta=LZW113_1.trim.contigs.good.unique.align, count=LZW113_1.trim.contigs.good.count_table)
```

这里，在summary的时候，有可能出现这一错误：

```pre
[ERROR]: Your count file contains 6400841 unique sequences, but your fasta file contains 3777293. File mismatch detected, quitting command.
```

很有可能是**data clean或demux的过程出现了问题**，导致很多序列比对不上去。如果排除这些原因，可以这样来继续：

```shell
perl -lanE 'if ($switch) {say if (/^Re/ || exists $need{$F[0]})} else {$need{$1}++ if />(.+)$/} $switch++ if eof(ARGV)' stability.trim.contigs.good.unique.align stability.trim.contigs.good.count_table > stability.trim.contigs.good.filter.count_table
mv stability.trim.contigs.good.count_table stability.trim.contigs.good.count_table.bak
mv stability.trim.contigs.good.filter.count_table stability.trim.contigs.good.count_table
```

因为count table的格式：

```pre
Representative_Sequence total   LZW113
FCAVD1Y_1_1112_19272_5098       1       1
FCAVD1Y_1_2105_6942_8265        1037    1037
FCAVD1Y_1_1113_27631_16492      1       1
FCAVD1Y_1_2110_13690_19012      1       1
FCAVD1Y_1_2113_9095_17142       12      12
FCAVD1Y_1_2107_11955_8783       1       1
FCAVD1Y_1_1104_12000_5514       1       1
FCAVD1Y_1_1113_19468_4747       1       1
FCAVD1Y_1_2102_16601_17755      1       1
```

而alignment的ID格式（类fasta文件）：

```shell
grep ">" stability.trim.contigs.good.unique.align |head
```

```pre
>FCAVD1Y_1_1112_19272_5098
>FCAVD1Y_1_2105_6942_8265
>FCAVD1Y_1_1113_27631_16492
>FCAVD1Y_1_2110_13690_19012
>FCAVD1Y_1_2113_9095_17142
>FCAVD1Y_1_2107_11955_8783
>FCAVD1Y_1_1104_12000_5514
>FCAVD1Y_1_1113_19468_4747
>FCAVD1Y_1_2102_16601_17755
>FCAVD1Y_1_2103_6545_6854
```

所以如果序列数目不一致的话，是可以把count table剪一剪拿去用的。

过长的contigs一般是由于拼接错误，需要去掉。因此`screen.seqs()`中的`maxlength`参数值建议选择97.5%-tile而小于Maximum的某个值（这样至多损失2.5%不到的数据，却可以去掉多数异常的序列）。

使用`nohup mothur screenContigs2SummaryAlignments.batch > step2.log &`完成这一部分的分析。

比对结束后，如果见到类似这种警告信息，是正常的：

```pre
[WARNING]: 1145 of your sequences generated alignments that eliminated too many bases, a list is provided in LZW113_1.trim.contigs.good.unique.flip.accnos.
```

**少量**的序列比对不上没什么问题。如果很多，就要检查一下了。

此外，应该注意汇报的alignments长度，以便于确定下一步的长度控制：

```pre
mothur > summary.seqs(fasta=LZW113_1.trim.contigs.good.unique.align, count=LZW113_1.trim.contigs.good.count_table)

Using 56 processors.

		Start	End	NBases	Ambigs	Polymer	NumSeqs
Minimum:	1	5	2	0	1	1
2.5%-tile:	2	11344	299	0	4	188178
25%-tile:	2	11344	302	0	4	1881778
Median: 	2	11344	304	0	4	3763556
75%-tile:	2	11344	304	0	5	5645333
97.5%-tile:	2	11344	308	0	7	7338933
Maximum:	11340	11344	388	0	9	7527110
Mean:	4	11343	303	0	4
# of unique seqs:	4693900
total # of seqs:	7527110

It took 539 secs to summarize 7527110 sequences.
```

这里很明显[2, 11344]是正确的区间。进入下一步。

## 第四部分：去除无用序列

*screenAlignments2RemoveLineage.batch* 的内容：

```shell
screen.seqs(fasta=LZW113_1.trim.contigs.good.unique.align, count=LZW113_1.trim.contigs.good.count_table, summary=LZW113_1.trim.contigs.good.unique.summary, start=2, end=11344, maxhomop=8, processors=20)
summary.seqs(fasta=current, count=current)
filter.seqs(fasta=LZW113_1.trim.contigs.good.unique.good.align, vertical=T, trump=.)
unique.seqs(fasta=LZW113_1.trim.contigs.good.unique.good.filter.fasta, count=LZW113_1.trim.contigs.good.good.count_table)
pre.cluster(fasta=LZW113_1.trim.contigs.good.unique.good.filter.unique.fasta, count=LZW113_1.trim.contigs.good.unique.good.filter.count_table, diffs=3)
chimera.vsearch(fasta=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.fasta, count=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.count_table, dereplicate=t)
remove.seqs(fasta=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.fasta, accnos=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.accnos)
summary.seqs(fasta=current, count=current)
classify.seqs(fasta=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, count=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.count_table, reference=silva.nr_v132.align, taxonomy=silva.nr_v132.tax, cutoff=80, iters=1000)
remove.lineage(fasta=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, count=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.count_table, taxonomy=LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.pick.nr_v132.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Eukaryota)
summary.tax(taxonomy=current, count=current)
```

这其中，`screen.seqs()`的`start`和`end`参数以及`pre.cluster()`的`diff`参数（**每100bp允许一个错配**）应该根据alignmnets的统计结果来确定。另外要保证**有vsearch预先安装好**（加入PATH变量，可直接调用）。在`remove.lineage()`中，由于**古细菌也是我们关注的对象，因此不予去除**；但是线粒体、叶绿体等等要去掉。
运行过程中，在`classify.seqs()`步骤可能会看到如下警告信息：

```pre
[WARNING]: FCAVD1Y_1_2108_24941_22154 could not be classified. You can use the remove.lineage command with taxon=unknown; to remove such sequences.
```

不必担心，我们在接下来的确就是这样做的。

## 插曲：重命名

流程进行到这里，mothur为中间结果自动添加的文件名前缀已经很冗长，为了方便接下来从构建OTU开始的分析，将关键的结果文件重命名为较短的形式比较方便。

*rename.batch* 的内容：

```shell
system(cp LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.pick.nr_v132.wang.pick.taxonomy LZW113_1.final.taxonomy)
system(cp LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta LZW113_1.final.fasta)
system(cp LZW113_1.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.count_table LZW113_1.final.count_table)
```

这样，*LZW113_1.final.taxonomy* 、*LZW113_1.final.fasta* 和*LZW113_1.final.count_table* 算作是**所有预处理都进行完毕**的数据了，重命名之后文件名很短，可以很方便传入OTU及其下游的分析。

## OTU分析

*OTU.batch* 的内容：

```shell
cluster.split(fasta=LZW113_1.final.fasta, count=LZW113_1.final.count_table, taxonomy=LZW113_1.final.taxonomy, splitmethod=classify, taxlevel=4, cutoff=0.20, processors=50)
make.shared(list=LZW113_1.final.opti_mcc.list, count=LZW113_1.final.count_table, label=0.20)
classify.otu(list=LZW113_1.final.opti_mcc.list, count=LZW113_1.final.count_table, taxonomy=LZW113_1.final.taxonomy, label=0.20)
```

`taxlevel=4`是指定使用上面的分类信息到第四级（界门纲目科属种的目），`cutoff`这个值很关键，mothur会只读取distance小于这个值的记录参与计算，如果太高，计算的时候生成的临时文件太大，会很吃硬盘资源（动辄几T），没有这种必要，且容易因为硬盘空间不足而中断。

选择这里作为断点，也是因为形成OTU是比较关键的承上启下的一步，如果参数有必要调节（尝试性的分析）则比较方便。

make.biom(shared=final.tx.1.subsample.1.pick.shared, constaxonomy=final.tx.1.cons.taxonomy)
biom convert -i GF.opti_mcc.0.03.biom -o table.from_biom_w_consensuslineage.txt --to-tsv --header-key taxonomy --output-metadata-id "ConsensusLineage" --table-type="OTU table"